# -*- coding: utf-8 -*-
"""Stacked LSTM-4 layer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AFHiAgRXT0Mh1mArey0egyud1eXE7BBJ
"""

!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
import pickle
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()

import numpy as np


drive = GoogleDrive(gauth)
file_id_data = '1DY1L5MiUXxi0B83g7Ka6q0XEp0A5PB4d'
downloaded = drive.CreateFile({'id': file_id_data})
downloaded.GetContentFile('InterpolatedTotalTrafficDataSet-03-2014.csv')

import xml.etree.ElementTree as ET
import urllib
import re
import io
import random
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
import pandas as pd
import time
from datetime import datetime
from sklearn.svm import SVR
import datetime
from keras.layers.core import Dense, Activation, Dropout
from keras.layers.recurrent import LSTM
from keras.models import Sequential
from math import sqrt
import time
from sklearn.metrics import mean_squared_error
import matplotlib
from matplotlib import pyplot
# be able to save images on server
matplotlib.use('Agg')
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from pandas import Series


#constant parameters
TrainingWindow = 53    #window size is found from historical data
PredictionWindow = 3   #prediction window/prediction horizon
time_sampling = 0.1	#Should be equal to data refreshing time

#normalizing data
def timeseries_to_supervised(data, lag=1):
    df = pd.DataFrame(data)
    columns = [df.shift(i) for i in range(1, lag + 1)]
    columns.append(df)
    df = pd.concat(columns, axis=1)
    df.fillna(0, inplace=True)
    #print("df is:",df)
    return df

# create a differenced series
def difference(dataset, interval=1):
    diff = list()
    for i in range(interval, len(dataset)):
        value = dataset[i] - dataset[i - interval]
        diff.append(value)
    #print("diff is:",diff)
    return Series(diff)

# invert differenced value
def inverse_difference(history, yhat, interval=1):
    return yhat + history[-interval]

def scale(train, test):
	# fit scaler
    #print("train is",train)
    #print("test is", test)
    scaler = MinMaxScaler(feature_range=(-1, 1))
    scaler = scaler.fit(train)

    # transform train
    train = train.reshape(train.shape[0], train.shape[1])
    train_scaled = scaler.transform(train)
    # transform test
    test = test.reshape(test.shape[0], test.shape[1])
    test_scaled = scaler.transform(test)
    return scaler, train_scaled, test_scaled


# inverse scaling for a forecasted value
def invert_scale(scaler, X, value):
    new_row = [x for x in X] + [value]
    array = np.array(new_row)
    array = array.reshape(1, len(array))
    inverted = scaler.inverse_transform(array)
    return inverted[0, -1]

# fit an LSTM network to training data
def fit_lstm(train, batch_size, nb_epoch, neurons):
    X, y = train[:, 0:-1], train[:, -1]
    #print('X is:', X)
    #print('X.shape[0] is:', X.shape[0])
    #print('X.shape[1] is:', X.shape[1])
    X = X.reshape(X.shape[0], 1, X.shape[1])
    #print('X is:',X)
    model = Sequential()
    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]),return_sequences=True, stateful=True))
    model.add(LSTM(neurons, return_sequences=True, stateful=True))
    model.add(LSTM(neurons, return_sequences=True, stateful=True))
    model.add(LSTM(neurons))
    model.add(Dense(1))
    model.compile(loss='mean_squared_error', optimizer='adam')
    for i in range(nb_epoch):
        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)
        model.reset_states()
    return model

# make a one-step forecast
def forecast_lstm(model, batch_size, X):
	X = X.reshape(1, 1, len(X))
	yhat = model.predict(X, batch_size=batch_size)
	return yhat[0,0]

def time_h_m(df):
    X = []
    for index, row in df.iterrows():
        X.append([index.hour, index.minute])

    return X

#adaptive moving window regression function
def My_Prediction_Method(df):
    #extracting last readings equivalent to window size

    length = len(df)

    df1 = df[length-TrainingWindow:length]

        ##SPEED##

    df_speed = df1[['Date_UTC','TrafficSpeed']]
    df_speed1 = df_speed.set_index('Date_UTC')
    new_index_s = pd.to_datetime(df_speed1.index, format='%Y-%m-%d %H:%M:%S')  #converting string data to format of datetime
    df_speed02 = df_speed1.reindex(new_index_s) #changing index
    df_speed2 = pd.DataFrame(df_speed02)
    X_speed = time_h_m(df_speed2)

    # transform data to be stationary
    df_speed2_values = df_speed.TrafficSpeed.values

    speed2_diff_values = difference(df_speed2_values, 1)

    # transform data to be supervised learning
    df_speed2_supervised = timeseries_to_supervised(speed2_diff_values,1)
    df_speed2_supervised_values = df_speed2_supervised.values

    # split data into train and test-sets
    train_speed, test_speed = df_speed2_supervised_values[0:-3], df_speed2_supervised_values[-3:]

    # transform the scale of the data
    scaler_speed, train_speed_scaled, test_speed_scaled = scale(train_speed, test_speed)
    #print("df_speed2_values", df_speed2_values,
         # "speed2_diff_values", speed2_diff_values,
         # "df_speed2_supervised", df_speed2_supervised,
         # "df_speed2_supervised_values", df_speed2_supervised_values)



        ##INTENSITY##

    df_intensity = df1[['Date_UTC', 'TrafficIntensity']]
    df_intensity1 = df_intensity.set_index('Date_UTC')
    new_index_s = pd.to_datetime(df_intensity1.index,format='%Y-%m-%d %H:%M:%S')  # converting string data to format of datetime
    df_intensity02 = df_intensity1.reindex(new_index_s)  # changing index
    df_intensity2 = pd.DataFrame(df_intensity02)
    #print("df_intensity2 is:", df_intensity2)
    X_intensity = time_h_m(df_intensity2)

    # transform data to be stationary
    df_intensity2_values = df_intensity.TrafficIntensity.values
    intensity2_diff_values = difference(df_intensity2_values, 1)

    # transform data to be supervised learning
    df_intensity2_supervised = timeseries_to_supervised(intensity2_diff_values, 1)
    df_intensity2_supervised_values = df_intensity2_supervised.values

    # split data into train and test-sets
    train_intensity, test_intensity = df_intensity2_supervised_values[0:-3], df_intensity2_supervised_values[-3:]

    # transform the scale of the data
    scaler_intensity, train_intensity_scaled, test_intensity_scaled = scale(train_intensity, test_intensity)







    # fit the model
    lstm_model_speed = fit_lstm(train_speed_scaled, 1, 3000, 4)
    lstm_model_intensity = fit_lstm(train_intensity_scaled, 1, 3000, 4)

    # forecast the entire training dataset to build up state for forecasting
    train_speed_reshaped = train_speed_scaled[:, 0].reshape(len(train_speed_scaled), 1, 1)
    lstm_model_speed.predict(train_speed_reshaped, batch_size=1)

    train_intensity_reshaped = train_intensity_scaled[:, 0].reshape(len(train_intensity_scaled), 1, 1)
    lstm_model_intensity.predict(train_intensity_reshaped, batch_size=1)

    # walk-forward validation on the test data

    predictions_speed = list()
    predictions_intensity = list()
    for i in range(len(test_speed_scaled)):

        # make one-step forecast
        X_s, y_s = test_speed_scaled[i, 0:-1], test_speed_scaled[i, -1]
        yhat_speed = forecast_lstm(lstm_model_speed, 1, X_s)

        X_i, y_i = test_intensity_scaled[i, 0:-1], test_intensity_scaled[i, -1]
        yhat_intensity = forecast_lstm(lstm_model_intensity, 1, X_i)

        # invert scaling
        yhat_speed = invert_scale(scaler_speed, X_s, yhat_speed)
        yhat_intensity = invert_scale(scaler_intensity, X_i, yhat_intensity)

        # invert differencing
        yhat_speed = inverse_difference(df_speed2_values, yhat_speed, len(test_speed_scaled) + 1 - i)
        yhat_intensity = inverse_difference(df_intensity2_values, yhat_intensity, len(test_intensity_scaled) + 1 - i)

        # store forecast
        predictions_speed.append(yhat_speed)
        predictions_intensity.append(yhat_intensity)

        expected_speed = df_speed2_values[len(train_speed) + i + 1]
        expected_intensity = df_intensity2_values[len(train_intensity) + i + 1]

        print("predicted traffic speed at {}:{} is {} and expected is {} ".format(X_speed[len(train_speed_scaled) + i + 1][0], X_speed[len(train_speed_scaled) + i + 1][1], yhat_speed, expected_speed ))
        print("predicted traffic intensity at {}:{} is {} and expected is {} ".format(X_intensity[len(train_intensity_scaled) + i + 1][0], X_speed[len(train_intensity_scaled) + i + 1][1], yhat_intensity, expected_intensity))



    # report performance
    rmse = sqrt(mean_squared_error(df_speed2_values[-3:], predictions_speed))
    print('Speed Test RMSE: %.3f' % rmse)
    
    rmse = sqrt(mean_squared_error(df_intensity2_values[-3:], predictions_intensity))
    print('Intensity Test RMSE: %.3f' % rmse)
    # line plot of observed vs predicted
    #pyplot.plot(df_speed2_values[-3:])
    #pyplot.plot(predictions)
    #pyplot.show()



    print("========================================================================================================")





#main function
if __name__ == '__main__':

    # while(1):
    ID = 'PM20412'

    df = pd.read_csv('InterpolatedTotalTrafficDataSet-03-2014.csv')

    df3 = df[df['ID'] == ID]
    # print('df3 is:',df3)

    df1 = pd.DataFrame(columns=['Date_UTC', 'ID', 'TrafficIntensity', 'TrafficOccupancy',
                                'TrafficSpeed'])  # defining an empty dataframe

    for index, row in df3.iterrows():

        # df2 = pd.DataFrame(row)
        # print("df2 is:", df2)
        df1 = df1.append(row)
        # print("df1 is:", df1)

        print('len of df1 is: ', len(df1))

        if len(df1) >= TrainingWindow:
            print("calling prediction algo")
            # print ("df1 is ", df1)
            My_Prediction_Method(df1)

        else:
            pass

            # print ("i am sleeping")
        time.sleep(time_sampling)